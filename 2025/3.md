# MapReduce

Modified: 250128

map: generate KV, reduce: merge KV  
deal with large amount of data  
idea from Lisp and other functional programming languages  

map and reduce contains a user function  
in google, large cluster PC with switchable ethernet  

map: split data into splits  
reduce: using a partitioning function  
output to R separated files ready for next MapReduce  

ping the workers periodically, mark the failed workers  
set IDLE state, read the data from worker to worker  
send messages to the master  
atomic rename operation  
time complexity: addition of map and reduce  

GFS: cut file into 64MB blocks with their backups  
R: considered by users  
M = 200, 000 and
R = 5, 000, using 2,000 worker machines  
provide special partitioning functions  
use partial combining  
reader: a set of input data types  

worker has a single handler to detect faults  
send UDP packet to master  
status page: failed workers, working process etc.  
counter: collected from workers, send to user by master  
grep, sort in library  
pre-pass MapReduce operation  
still functioning properly after kill threads manually  

use for google searching: simpler indexing code, good enough for performance, easy enough for operate  
