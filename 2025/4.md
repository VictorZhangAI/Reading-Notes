# Google File System

Modified: 250129

meet the growing data processing needs  
huge files by traditional standards  
append more than overwrite  
co-design the file system and its API  

built on inexpensive components, ability to handle faults  
hold large files, no need to suit for small files  
large streaming read, small random read, once written, seldom modified  
producer-consumer queue for multiple clients  
high band-width  
single master, multiple chunkservers, access by clients  
master maintains all metadata  
communicate with chunkserver with heartbeat messages  
no POSIX api, no vnode layer  

reply with corresponding chunk handle, client send request to the nearest replica  
chunksize: much larger than common chunk in file systems  
large chunksize lets the chunkserver less likely to interact with master, let client do more operation on the same chunk  
higher replication factor & making a batch queue  
operation log in the master, ask the chunkserver whether join the cluster or not  
memory-holding: let the master more fast  
poll chunkserver for information to startup  
operation log: critical metadata changes  
multiple remote machine, flush fault chunks  
create checkpoints including all switches  

file rename atomically  
consistent: all servers found the data  
defined: after its consistent  
writes&appends: atomic at least once  
regular handshakes checking whether data is crash  

primary: move chunk to the replica  
steps of write:  
client asks the master where the chunk is  
master reply with identity  
client push data to replica  
client send request to primary  
forward th write request to secondary  
hierarchical replication to the client finally  

data pushed linearly in queues  
fully utilize high-bandwidth network  
primary check whether append could fill into a  chunk  

use copy-on-write to apply snapshot features  
create the new chunk on the chunkserver locally to make copies right on the server  

demand: master no delay for massive operations happen on chunkserver  
no per-directory structure, no alises  
nodes in namespace tree  
apply locks in file system, provide parent directory from deletion  
read-and-write lock are allocated and deleted lazily  
chunk replicas: chunk creation, re-replication, rebalancing  

lazy garbage collection, regular scanning  
simple but reliable, done only when master is free  
maintain chunk version number  
we cannot completely trust machine and disks  
fast recovery, chunk replication  

use checksums to ensure the integrity of data  

RPC requests & replies  
using RPC logs and RPC replies to backtrace the problems  
micro-benchmarks  
challenges: fsync(), mmap() and locks  
River Model  
